{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9a0412-43fb-4ac5-af63-8ef68f1e2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import dask\n",
    "import re\n",
    "import scipy.stats as stats\n",
    "import scipy.signal as signal\n",
    "from skimage.measure import find_contours\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "import isla_interp_utils as isla_interp\n",
    "\n",
    "# Plotting utils \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c5606f-8d69-427a-aa8f-cec2c9bf4acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_data(fromthis, tothis, method=1):\n",
    "    \"\"\"Regrid data using various different methods\"\"\"\n",
    "\n",
    "    #Import necessary modules:\n",
    "    import xarray as xr\n",
    "\n",
    "    if method == 1:\n",
    "        # kludgy: spatial regridding only, seems like can't automatically deal with time\n",
    "        if 'time' in fromthis.coords:\n",
    "            result = [fromthis.isel(time=t).interp_like(tothis) for t,time in enumerate(fromthis['time'])]\n",
    "            result = xr.concat(result, 'time')\n",
    "            return result\n",
    "        else:\n",
    "            return fromthis.interp_like(tothis)\n",
    "    elif method == 2:\n",
    "        newlat = tothis['lat']\n",
    "        newlon = tothis['lon']\n",
    "        coords = dict(fromthis.coords)\n",
    "        coords['lat'] = newlat\n",
    "        coords['lon'] = newlon\n",
    "        return fromthis.interp(coords)\n",
    "    elif method == 3:\n",
    "        newlat = tothis['lat']\n",
    "        newlon = tothis['lon']\n",
    "        ds_out = xr.Dataset({'lat': newlat, 'lon': newlon})\n",
    "        regridder = xe.Regridder(fromthis, ds_out, 'bilinear')\n",
    "        return regridder(fromthis)\n",
    "    elif method==4:\n",
    "        # geocat\n",
    "        newlat = tothis['lat']\n",
    "        newlon = tothis['lon']\n",
    "        result = geocat.comp.linint2(fromthis, newlon, newlat, False)\n",
    "        result.name = fromthis.name\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00d2472d-8b26-4d82-a2ef-6e8f53308631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbed from Brian M. to use time midpoints, not end periods\n",
    "def cesm_correct_time(ds):\n",
    "    \"\"\"Given a Dataset, check for time_bnds,\n",
    "       and use avg(time_bnds) to replace the time coordinate.\n",
    "       Purpose is to center the timestamp on the averaging inverval.   \n",
    "       NOTE: ds should have been loaded using `decode_times=False`\n",
    "    \"\"\"\n",
    "    assert 'time_bnds' in ds\n",
    "    assert 'time' in ds\n",
    "    correct_time_values = ds['time_bnds'].mean(dim='nbnd')\n",
    "    # copy any metadata:\n",
    "    correct_time_values.attrs = ds['time'].attrs\n",
    "    ds = ds.assign_coords({\"time\": correct_time_values})\n",
    "    ds = xr.decode_cf(ds)  # decode to datetime objects\n",
    "    return ds\n",
    "\n",
    "# - - - - - - - - - - - - - - - \n",
    "# Pre-process data while reading in \n",
    "# - - - - - - - - - - - - - - - \n",
    "\n",
    "def preprocess(ds):\n",
    "    dsCorr         = cesm_correct_time(ds)\n",
    "    dsCorr         = dsCorr.sel(lat=slice(-10,10))\n",
    "    \n",
    "    return dsCorr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6785d7-a863-4ae0-a8ae-f96fe9fa3650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953e5169-aa3b-4af7-a326-3cc4951c3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some basics - the region to focus on, for one\n",
    "lat_n = 10.0\n",
    "lat_s = -10.0\n",
    "\n",
    "# Nino3.4\n",
    "lat_n34 = 5\n",
    "lat_s34 = -5\n",
    "lon_e34 = 190 \n",
    "lon_w34 = 240\n",
    "\n",
    "# Nino3\n",
    "lat_n3 = 5\n",
    "lat_s3 = -5\n",
    "lon_e3 = 210 \n",
    "lon_w3 = 270\n",
    "\n",
    "# Nino 4\n",
    "lat_n4 = 5\n",
    "lat_s4 = -5\n",
    "lon_e4 = 160 \n",
    "lon_w4 = 210\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8677a817-43f2-401b-b4dd-380401c23d1c",
   "metadata": {},
   "source": [
    "## Read in CESM1/CESM2 PI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7407125b-6a12-4466-8a90-45975c2827cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'ts' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'ts' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'ts' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'ts' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'ts' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'ts' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'ts' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'ts' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'ts' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'ts' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'ts' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n",
      "/glade/u/apps/opt/conda/envs/npl-2024a/lib/python3.11/site-packages/xarray/conventions.py:448: SerializationWarning: variable 'ts' has multiple fill values {1e+20, 1e+20}, decoding all values to NaN.\n",
      "  new_vars[k] = decode_cf_variable(\n"
     ]
    }
   ],
   "source": [
    "cesm2_dir = '/glade/campaign/collections/cdg/data/CMIP6/CMIP/NCAR/CESM2/piControl/r1i1p1f1/Amon/ts/gn/files/d20190320/'\n",
    "cesm1_dir = '/glade/campaign/cesm/collections/cesmLE/CESM-CAM5-BGC-LE/atm/proc/tseries/monthly/TS/'\n",
    "\n",
    "listFiles_cesm1 = np.sort(glob.glob(cesm1_dir+'b.e11.B1850C5CN.f09_g16.005.cam.h0.TS.*nc'))\n",
    "listFiles_cesm2 = np.sort(glob.glob(cesm2_dir+'ts_Amon_CESM2_piControl_r1i1p1f1_gn*.nc'))\n",
    "\n",
    "DS_all_cesm1 = xr.open_mfdataset(listFiles_cesm1, preprocess=preprocess, concat_dim='time', combine='nested', \n",
    "                                 decode_times=False, data_vars='minimal', parallel=True)\n",
    "\n",
    "DS_all_cesm2 = xr.open_mfdataset(listFiles_cesm2, \n",
    "                                 preprocess=preprocess, concat_dim='time', combine='nested', \n",
    "                                 decode_times=False, data_vars='minimal', parallel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1be10a68-1c79-4983-adfc-244390ac7940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CESM1 has 1801 years.\n",
      "CESM2 has 1200 years.\n",
      "Creating 30 samples to compute ENSO over, starting every 40 years and each with a window of 40 years.\n",
      "CPU times: user 35 s, sys: 1.98 s, total: 37 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "nYears_cesm1 = len(DS_all_cesm1.time.values)/12\n",
    "nYears_cesm2 = len(DS_all_cesm2.time.values)/12\n",
    "print('CESM1 has %i years.\\nCESM2 has %i years.' % (nYears_cesm1,nYears_cesm2) )\n",
    "\n",
    "# n_spacing    = int(25)\n",
    "# nYearsPer    = int(50)\n",
    "n_spacing    = int(40)\n",
    "nYearsPer    = int(40)\n",
    "# nSamples  = int(np.floor(np.nanmin([((nYears_cesm1 - nYearsPer) // n_spacing + 1), ((nYears_cesm2 - nYearsPer) // n_spacing + 1)])) )\n",
    "nSamples  = int(np.floor(np.nanmin([((nYears_cesm1 - nYearsPer) // n_spacing + 1), ((nYears_cesm2 - nYearsPer) // n_spacing + 1)])) )\n",
    "print('Creating %i samples to compute ENSO over, starting every %i years and each with a window of %i years.' % (nSamples, n_spacing, nYearsPer))\n",
    "\n",
    "#nStartInd = np.arange(0, nSamples*12, n_spacing*12)\n",
    "\n",
    "# Create an empty array to store the reshaped data\n",
    "events_cesm1 = np.zeros([nSamples, nYearsPer*12, len(DS_all_cesm1.lat.values), len(DS_all_cesm1.lon.values)])\n",
    "events_cesm2 = np.zeros([nSamples, nYearsPer*12, len(DS_all_cesm2.lat.values), len(DS_all_cesm2.lon.values)])\n",
    "\n",
    "# Create a new DataArray with the 'Event' axis\n",
    "event_coords = np.arange(nSamples)\n",
    "time_coords = np.arange(nYearsPer*12)\n",
    "\n",
    "# DS_events_cesm1 = xr.DataArray(events_cesm1, coords=[event_coords, time_coords, DS_all_cesm1.lat.values, DS_all_cesm1.lon.values], \n",
    "#                                dims=[\"event\", \"time\", \"lat\",\"lon\"])\n",
    "\n",
    "# DS_events_cesm2 = xr.DataArray(events_cesm2, coords=[event_coords, time_coords, DS_all_cesm2.lat.values, DS_all_cesm2.lon.values], \n",
    "                               # dims=[\"event\", \"time\", \"lat\",\"lon\"])\n",
    "\n",
    "## Loop over the events and fill the new array\n",
    "for iENSO in range(nSamples):\n",
    "    start_year = iENSO * (n_spacing*12)\n",
    "    events_cesm1[iENSO, :, :,:] = DS_all_cesm1.TS.isel(time=slice(start_year, (start_year + nYearsPer*12)))\n",
    "    events_cesm2[iENSO, :, :,:] = DS_all_cesm2.ts.isel(time=slice(start_year, (start_year + nYearsPer*12)))\n",
    "\n",
    "    # print('Starting with time index %i' % (start_year))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91007ed9-3017-4342-95f8-ea59082c404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataArray with the 'Event' axis\n",
    "event_coords = np.arange(nSamples)\n",
    "# time_coords  = DS_all_cesm1.time.values[17400:18000]\n",
    "time_coords  = DS_all_cesm1.time.values[17400:(17400+(nYearsPer*12))]\n",
    "\n",
    "DS_cesm1_events = xr.DataArray(events_cesm1, coords=[event_coords, time_coords, DS_all_cesm1.lat.values, DS_all_cesm1.lon.values], \n",
    "                               dims=[\"event\", \"time\", \"lat\",\"lon\"])\n",
    "\n",
    "\n",
    "DS_cesm2_events = xr.DataArray(events_cesm2, coords=[event_coords, time_coords, DS_all_cesm2.lat.values, DS_all_cesm2.lon.values], \n",
    "                               dims=[\"event\", \"time\", \"lat\",\"lon\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95ef73e-02d1-460c-ad21-b8b00ca91bcd",
   "metadata": {},
   "source": [
    "## Read in CESM3dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af3fbc3-5971-4305-a7fc-77286ae95e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "phis = xr.open_dataset(\"/glade/campaign/cesm/collections/CESM2-LE/atm/proc/tseries/month_1/PHIS/\"\n",
    "     +\"b.e21.BHISTcmip6.f09_g17.LE2-1001.001.cam.h0.PHIS.185001-185912.nc\").isel(time=0).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5374c508-ac13-4360-9b62-0cdf268bf846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_h0(DS):\n",
    "    climoVar_list = ['LHFLX','SHFLX','LWCF','SWCF','PRECT','PS','TAUX','TAUY','TGCLDLWP','U10','TREFHT','UBOT','TS']\n",
    "\n",
    "    dsSel = DS.sel(lat=slice(-10,10))\n",
    "\n",
    "    ## Interpolate to set levels \n",
    "    u850 = isla_interp.interp_hybrid_to_pressure(\n",
    "      dsSel.U, dsSel.PS, dsSel.hyam, dsSel.hybm, p0=1e5, new_levels = np.array([85000.]), method='log', \n",
    "      lev_dim='lev', extrapolate=False, variable='other',\n",
    "      t_bot = dsSel.T.isel(lev=dsSel.lev.size-1), phi_sfc = phis)\n",
    "\n",
    "    omega500 = isla_interp.interp_hybrid_to_pressure(\n",
    "      dsSel.OMEGA, dsSel.PS, dsSel.hyam, dsSel.hybm, p0=1e5, new_levels = np.array([50000.]), method='log', \n",
    "      lev_dim='lev', extrapolate=False, variable='other',\n",
    "      t_bot = dsSel.T.isel(lev=dsSel.lev.size-1), phi_sfc = phis)\n",
    "    \n",
    "    \n",
    "    # u850  = DS.sel(lev=850, method='nearest').U\n",
    "    dsSel = dsSel[climoVar_list]\n",
    "    dsSel['U850'] = u850\n",
    "    dsSel['OMEGA500'] = omega500\n",
    "    \n",
    "    return dsSel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8658f-3ed2-4d33-a321-164ce5a47f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = '/glade/derecho/scratch/hannay/archive/'\n",
    "caseNames = ['b.e30_beta04.BLT1850.ne30_t232_wgx3.121', \n",
    "             'b.e30_beta04.BLTHIST.ne30_t232_wgx3.121', \n",
    "             'b.e30_beta04.BLT1850.ne30_t232_wgx3.121_1pctco2',\n",
    "             'b.e30_beta04.BLT1850.ne30_t232_wgx3.121_4xco2',\n",
    "             'b.e30_beta05.BLT1850.ne30_t232_wgx3.125',\n",
    "            ]\n",
    "shortNames = ['121_preInd', \n",
    "              '121_hist',\n",
    "              '121_1pctCO2',\n",
    "              '121_4xCO2',\n",
    "              '125',\n",
    "             ]\n",
    "\n",
    "for iCase in range(len(caseNames)):\n",
    "    listFiles = np.sort(glob.glob(dataDir+caseNames[iCase]+'/atm/hist/'+'*.h0a.*.nc'))\n",
    "\n",
    "    camDS = xr.open_mfdataset(listFiles, preprocess=preprocess_h0, concat_dim='time', combine='nested', \n",
    "                                 decode_times=True, data_vars='minimal', parallel=True)\n",
    "\n",
    "    caseDS   = camDS.squeeze().assign_coords({\"case\":  shortNames[iCase]})\n",
    "\n",
    "    if iCase==0:\n",
    "        camDS_all = caseDS\n",
    "    else: \n",
    "        camDS_all = xr.concat([camDS_all, caseDS], \"case\") \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4810a5c2-b411-4db0-819a-e3da77e68397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed63af06-23cf-4ebb-8154-b8b33c35fcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8376a-5f15-46d1-bf9b-8715e6827a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d693e-7781-4927-8081-a5624527fbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74948c67-218c-4716-a6a4-826f4cd104c6",
   "metadata": {},
   "source": [
    "## Get anomalies and SSTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58555f75-89f3-47da-9c75-d25a87f0c1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65865a21-f5b3-4965-96a5-37f31a5b766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute anomalies\n",
    "\n",
    "# Detrend data \n",
    "SST = cesm2_sst.ts.values\n",
    "##   This is a little wonky because signal.detrend can't handle NaNs so replacing with a marker that we mask later\n",
    "sst_detrend = signal.detrend(SST, axis=0, type='linear')\n",
    "\n",
    "PRECT = cesm2_pr.pr \n",
    "prect_detrend = signal.detrend(PRECT, axis=0, type='linear')\n",
    "\n",
    "U850 = cesm2_u850.ua\n",
    "##   This is a little wonky because signal.detrend can't handle NaNs so replacing with a marker that we mask later\n",
    "u850_Fill = U850.values\n",
    "u850_Fill[(np.isnan(u850_Fill))] = -99\n",
    "u850_detrend = signal.detrend(u850_Fill, axis=0, type='linear')\n",
    "\n",
    "TAUX = cesm2_taux.tauu\n",
    "taux_detrend = signal.detrend(TAUX, axis=0, type='linear')\n",
    "\n",
    "\n",
    "# Get ocean values only \n",
    "cesm2_prect = prect_detrend * cesm2_ocnMask\n",
    "cesm2_sst   = sst_detrend * cesm2_ocnMask\n",
    "cesm2_u850  = u850_detrend * cesm2_ocnMask\n",
    "cesm2_taux  = taux_detrend * cesm2_ocnMask\n",
    "\n",
    "# Also remove annual cycle\n",
    "cesm2_sst = xr.DataArray(cesm2_sst, \n",
    "    coords={'time': cesm2_pr.time.values,\n",
    "            'lat':  cesm2_pr.lat.values, \n",
    "            'lon':  cesm2_pr.lon.values}, \n",
    "    dims=[\"time\", \"lat\", \"lon\"])\n",
    "\n",
    "cesm2_prect = xr.DataArray(cesm2_prect, \n",
    "    coords={'time': cesm2_pr.time.values,\n",
    "            'lat':  cesm2_pr.lat.values, \n",
    "            'lon':  cesm2_pr.lon.values}, \n",
    "    dims=[\"time\", \"lat\", \"lon\"])\n",
    "\n",
    "\n",
    "cesm2_u850 = xr.DataArray(cesm2_u850, \n",
    "    coords={'time': cesm2_pr.time.values,\n",
    "            'lat':  cesm2_pr.lat.values, \n",
    "            'lon':  cesm2_pr.lon.values}, \n",
    "    dims=[\"time\", \"lat\", \"lon\"])\n",
    "\n",
    "cesm2_taux = xr.DataArray(cesm2_taux, \n",
    "    coords={'time': cesm2_pr.time.values,\n",
    "            'lat':  cesm2_pr.lat.values, \n",
    "            'lon':  cesm2_pr.lon.values}, \n",
    "    dims=[\"time\", \"lat\", \"lon\"])\n",
    "\n",
    "\n",
    "sst_cesm2_anom   = rmMonAnnCyc(cesm2_sst)\n",
    "prect_cesm2_anom = rmMonAnnCyc(cesm2_prect)\n",
    "u850_cesm2_anom  = rmMonAnnCyc(cesm2_u850)\n",
    "taux_cesm2_anom  = rmMonAnnCyc(cesm2_taux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab6d02-e994-4dd9-85a2-76042fa0b939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024a",
   "language": "python",
   "name": "npl-2024a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
