import xarray as xr
import numpy as np
from datetime import date
import matplotlib.pyplot as plt
import warnings, os, yaml
import matplotlib
import getpass
import subprocess
import netCDF4
# mom6_tools
from mom6_tools.MOM6grid import MOM6grid
from mom6_tools.m6toolbox import genBasinMasks
from mom6_tools.m6plot import xyplot, ztplot
from mom6_tools.poleward_heat_transport import heatTrans, plotHeatTrans, plotGandW
import glob
import pop_tools

matplotlib.rcParams.update({'font.size': 18})
warnings.filterwarnings("ignore")

def cime_xmlquery(caseroot, varname):
    """run CIME's xmlquery for varname in the directory caseroot, return the value"""
    try:
        value = subprocess.check_output(
            ["./xmlquery", "-N", "--value", varname],
            stderr=subprocess.STDOUT,
            cwd=caseroot,
        )
    except subprocess.CalledProcessError:
        value = subprocess.check_output(
            ["./xmlquery", "--value", varname], stderr=subprocess.STDOUT, cwd=caseroot
        )
    return value.decode()

def count_word_occurrences(data, word):
    count = 0
    if isinstance(data, dict):
        for key, value in data.items():
            count += count_word_occurrences(key, word)
            count += count_word_occurrences(value, word)
    elif isinstance(data, list):
        for item in data:
            count += count_word_occurrences(item, word)
    elif isinstance(data, str):
        count += data.lower().split().count(word.lower())
    return count

# for plotting, the following was a feedback from Keith Lindsay.
linestyle = ['solid','solid','solid',
             'dashed','dashed','dashed',
             'dotted','dotted','dotted']
color = ['black','red','blue','black',
         'red','blue','black',
         'red','blue']
# check with Keith Lindsay
plt.style.use('tableau-colorblind10')

diag_config_yml = yaml.load(open('../diag_config.yml','r'),
                            Loader=yaml.Loader)
# initialize lists
casename=[]
label = []; OUTDIR=[]
ocn_path = []

word_to_search = 'Case'
ncases = count_word_occurrences(diag_config_yml, word_to_search)

ncases = len(diag_config_yml.keys()) - 3
print(ncases)
#ncases = len(diag_config_yml.keys()) - 1
if ncases < 2:
  # Create the case instance
  caseroot = diag_config_yml['Case']['CASEROOT']
  casename.append(cime_xmlquery(caseroot, 'CASE'))
  label.append(diag_config_yml['Case']['SNAME'])
  ocn_path.append(diag_config_yml['Case']['OCN_DIAG_ROOT'])
  DOUT_S = cime_xmlquery(caseroot, 'DOUT_S')
  if DOUT_S:
    out = cime_xmlquery(caseroot, 'DOUT_S_ROOT')+'/ocn/hist/'
  else:
    out = cime_xmlquery(caseroot, 'RUNDIR')+'/'

  OUTDIR.append(out)

else:
  for i in range(ncases):
    cname = 'Case{}'.format(i+1)
    caseroot = diag_config_yml[cname]['CASEROOT']
    casename.append(cime_xmlquery(caseroot, 'CASE'))
    label.append(diag_config_yml[cname]['SNAME'])
    ocn_path.append(diag_config_yml[cname]['OCN_DIAG_ROOT'])
    DOUT_S = cime_xmlquery(caseroot, 'DOUT_S')
    if DOUT_S:
      out = cime_xmlquery(caseroot, 'DOUT_S_ROOT')+'/ocn/hist/'
    else:
      out = cime_xmlquery(caseroot, 'RUNDIR')+'/'

    OUTDIR.append(out)

# set avg dates
avg = diag_config_yml['Avg']
start_date = avg['start_date']
end_date = avg['end_date']

print('Casename is {}'.format(casename))
print('─' * 60)
print('Averaged between {} and {}'.format(start_date, end_date))
print('─' * 60)
print('Output directory is:', OUTDIR)
print('─' * 60)
print('Generated by {}'.format(getpass.getuser()))
print('─' * 60)
print("Last update:", date.today())

grd = []
grd_xr = []
depth = []
basin_code = []

for i in range(len(casename)):
  #geom_file = glob.glob(OUTDIR[i]+'/*.mom6.h.ocean_geometry.nc')
  #if not os.path.exists(geom_file):
  geom_file = None
  print('Here1')

  # load grid and pre-difined masks
  fname = glob.glob(OUTDIR[i]+'*.static.nc')[0]
  grd.append(MOM6grid(fname, geom_file))
  grd_xr.append(MOM6grid(fname, geom_file, xrformat=True))
  try:
    # remote Nan's, otherwise genBasinMasks won't work
    depth_tmp=grd[i].depth_ocean
  except:
    depth_tmp=grd[i].deptho

  depth_tmp[np.isnan(depth_tmp)] = 0.0
  depth.append(depth_tmp)
  # remote Nan's, otherwise genBasinMasks won't work
  depth_mask = depth[i].copy()
  depth_mask[np.isnan(depth_mask)] = 0.0
  print(depth_mask.shape)
  print(grd[i])
  basin_code.append(genBasinMasks(grd[i].geolon, grd[i].geolat, depth_mask, xda=True))

# pop grid
pop_grid = pop_tools.get_grid('POP_gx1v7')

def get_heat_transport_obs():
    """Plots model vs obs poleward heat transport for the global, Pacific and Atlantic basins"""
    # Load Observations
    fObs = netCDF4.Dataset('/glade/work/gmarques/cesm/datasets/Trenberth_and_Caron_Heat_Transport.nc')
    #Trenberth and Caron
    yobs = fObs.variables['ylat'][:]
    NCEP = {}; NCEP['Global'] = fObs.variables['OTn']
    NCEP['Atlantic'] = fObs.variables['ATLn'][:]; NCEP['IndoPac'] = fObs.variables['INDPACn'][:]
    ECMWF = {}; ECMWF['Global'] = fObs.variables['OTe'][:]
    ECMWF['Atlantic'] = fObs.variables['ATLe'][:]; ECMWF['IndoPac'] = fObs.variables['INDPACe'][:]

    #G and W
    Global = {}
    Global['lat'] = np.array([-30., -19., 24., 47.])
    Global['trans'] = np.array([-0.6, -0.8, 1.8, 0.6])
    Global['err'] = np.array([0.3, 0.6, 0.3, 0.1])

    Atlantic = {}
    Atlantic['lat'] = np.array([-45., -30., -19., -11., -4.5, 7.5, 24., 47.])
    Atlantic['trans'] = np.array([0.66, 0.35, 0.77, 0.9, 1., 1.26, 1.27, 0.6])
    Atlantic['err'] = np.array([0.12, 0.15, 0.2, 0.4, 0.55, 0.31, 0.15, 0.09])

    IndoPac = {}
    IndoPac['lat'] = np.array([-30., -18., 24., 47.])
    IndoPac['trans'] = np.array([-0.9, -1.6, 0.52, 0.])
    IndoPac['err'] = np.array([0.3, 0.6, 0.2, 0.05,])

    GandW = {}
    GandW['Global'] = Global
    GandW['Atlantic'] = Atlantic
    GandW['IndoPac'] = IndoPac
    return NCEP, ECMWF, GandW, yobs

NCEP, ECMWF, GandW, yobs = get_heat_transport_obs()

def get_adv_diff(ds):
    # create a ndarray subclass
    class C(np.ndarray): pass

    varName = 'T_ady_2d'
    if varName in ds.variables:
        tmp = np.ma.masked_invalid(ds[varName].values)
        tmp = tmp[:].filled(0.)
        advective = tmp.view(C)
        advective.units = 'W'
    else:
        raise Exception('Could not find "T_ady_2d"')

    varName = 'T_diffy_2d'
    if varName in ds.variables:
        tmp = np.ma.masked_invalid(ds[varName].values)
        tmp = tmp[:].filled(0.)
        diffusive = tmp.view(C)
        diffusive.units = 'W'
    else:
        diffusive = None
        warnings.warn('Diffusive temperature term not found. This will result in an underestimation of the heat transport.')

    varName = 'T_hbd_diffy_2d'
    if varName in ds.variables:
        tmp = np.ma.masked_invalid(ds[varName].values)
        tmp = tmp[:].filled(0.)
        diffusive = diffusive + tmp.view(C)
    else:
        warnings.warn('Horizontal boundary mixing term not found. This will result in an underestimation of the heat transport.')

    return advective, diffusive

def plot_heat_trans(ds, label, linestyle='-'):
    adv, diff = get_adv_diff(ds)
    HT = heatTrans(adv,diff); y = ds.yq
    plt.plot(y, HT, linewidth=3, linestyle=linestyle, label=label)
    return

def heatTrans(advective, diffusive=None, hbd=None, vmask=None, units="W"):
  """Converts vertically integrated temperature advection/diffusion into heat transport"""
  HT = advective[:]
  if diffusive is not None:
    HT = HT + diffusive[:]
  if hbd is not None:
    HT = HT + hbd[:]
  if len(HT.shape) == 3:
    HT = HT.mean(axis=0)
  if units == "Celsius meter3 second-1":
    rho0 = 1.035e3
    Cp = 3992.
    HT = HT * (rho0 * Cp)
    HT = HT * 1.e-15  # convert to PW
  elif units == "W":
    HT = HT * 1.e-15
  else:
    print('Unknown units')
  if vmask is not None: HT = HT*vmask
  HT = HT.sum(axis=-1); HT = HT.squeeze() # sum in x-direction
  return HT

def pop_add_cyclic(ds):

    nj = ds.TLAT.shape[0]
    ni = ds.TLONG.shape[1]

    xL = int(ni/2 - 1)
    xR = int(xL + ni)

    tlon = ds.TLONG.data
    tlat = ds.TLAT.data

    tlon = np.where(np.greater_equal(tlon, min(tlon[:,0])), tlon-360., tlon)
    lon  = np.concatenate((tlon, tlon + 360.), 1)
    lon = lon[:, xL:xR]

    if ni == 320:
        lon[367:-3, 0] = lon[367:-3, 0] + 360.
    lon = lon - 360.

    lon = np.hstack((lon, lon[:, 0:1] + 360.))
    if ni == 320:
        lon[367:, -1] = lon[367:, -1] - 360.

    #-- trick cartopy into doing the right thing:
    #   it gets confused when the cyclic coords are identical
    lon[:, 0] = lon[:, 0] - 1e-8

    #-- periodicity
    lat = np.concatenate((tlat, tlat), 1)
    lat = lat[:, xL:xR]
    lat = np.hstack((lat, lat[:,0:1]))

    TLAT = xr.DataArray(lat, dims=('nlat', 'nlon'))
    TLONG = xr.DataArray(lon, dims=('nlat', 'nlon'))

    dso = xr.Dataset({'TLAT': TLAT, 'TLONG': TLONG})

    # copy vars
    varlist = [v for v in ds.data_vars if v not in ['TLAT', 'TLONG']]
    for v in varlist:
        v_dims = ds[v].dims
        if not ('nlat' in v_dims and 'nlon' in v_dims):
            dso[v] = ds[v]
        else:
            # determine and sort other dimensions
            other_dims = set(v_dims) - {'nlat', 'nlon'}
            other_dims = tuple([d for d in v_dims if d in other_dims])
            lon_dim = ds[v].dims.index('nlon')
            field = ds[v].data
            field = np.concatenate((field, field), lon_dim)
            field = field[..., :, xL:xR]
            field = np.concatenate((field, field[..., :, 0:1]), lon_dim)
            dso[v] = xr.DataArray(field, dims=other_dims+('nlat', 'nlon'),
                                  attrs=ds[v].attrs)


    # copy coords
    for v, da in ds.coords.items():
        if not ('nlat' in da.dims and 'nlon' in da.dims):
            dso = dso.assign_coords(**{v: da})


    return dso

pop_grid_o = pop_add_cyclic(pop_grid)

